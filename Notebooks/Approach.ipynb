{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approching a problem in  Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about how to approach different ML problems. How to go about those problems and which algorithm  to use and how to write the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have gone through one of the interview of Abhishek Thakur with Sayak and there he was asked how he learn about different things. There the GrandMaster said that he learn by applying different things on different problem set using this he learnt a lot of different things. This is what I also think that we should be doing --> instead of going directly for the SOTA we should start from the basic approach and build on that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So today I am starting on Resume filtering solution or Resume classification solution. I can start from simple logistic regression , naive bayes, Decision Tree, and Random Forest. Once we have applied these algos we can check which one is working and how they are working and what are the hyperparameter I can change. We know that RNN/Transformer  are the go to method for the NLP problems now a days but to get a better understanding on why they work and why the traditional algorithm didn't work we can do it in this way. For most of the NLP based classification problem we can build a pipeline sort of thing where our code is preprocessing everything and after that with few clicks we are able to apply different algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in Data Science we perform a lot of experiment. It will be very good if our code is modular. So instead of writing the same code or pasting the same code again and again it will be much better if we import there modules. In this way we will not be copying anything and it will be efficient too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So these will be my basic algorithm which I will be implementing - \n",
    "> * Logistic Regression\n",
    "> * Naive Bayes \n",
    "> * Decision Tree\n",
    "> * RandomForest\n",
    "> * K-Nearest Neighbour\n",
    "> * SVM ( Soft Vector Machine)\n",
    "> * SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before starting let us also think the preprocessing step or the EDA we can do for the NLP data -\n",
    "> * BagOfWords\n",
    "> * TfIdf\n",
    "> * Word2Vec\n",
    "> * SkipGram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing involves a lot of things in text data. Here is a link of different preprocessing steps in NLP. <br>\n",
    "\n",
    "<a href=\"https://www.kdnuggets.com/2019/04/text-preprocessing-nlp-machine-learning.html\"> Blog Link </a> <br> \n",
    "\n",
    "Methods discussed in blog are as follows - \n",
    "> * Lowercasing \n",
    "> * Stemming\n",
    "> * Lemmatization\n",
    "> * Stopword Removal\n",
    "> * Text Normalization\n",
    "> * Noise Removal\n",
    "> * Text Enrihment / Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
